# Transcriber - Dev Environment
# Kubernetes configuration for AI transcription service
# âš ï¸  HEAVY WORKLOAD: 8 CPU cores, 32Gi RAM for AI processing

# ğŸ–¼ï¸ Image Configuration
image:
  repository: us-east1-docker.pkg.dev/ritual-app-dev-104fc/docker/transcriber
  # tag is injected by CI/CD during rendering
  pullPolicy: Always

# ğŸ“Š Scaling
replicaCount: 1

# ğŸ’ª Resources (HEAVY AI WORKLOAD)
resources:
  requests:
    cpu: 2000m
    memory: 8Gi
  limits:
    cpu: 8000m
    memory: 32Gi

# ğŸ”„ Autoscaling
autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

# ğŸ›¡ï¸ Pod Disruption Budget
podDisruptionBudget:
  enabled: false

# ğŸŒ Service (Internal ClusterIP - no external access)
service:
  type: ClusterIP
  port: 8080
  targetPort: 8080
  annotations: {}

# ğŸŒ Gateway API Configuration
gateway:
  enabled: false  # No public gateway
  
  # ğŸ“š Additional routes for Swagger Gateway (IAP-protected)
  # Access swagger UI at: swagger.dev.ourritual.com/transcriber/swagger
  additionalRoutes:
    - name: swagger
      gatewayName: swagger-gateway
      gatewayNamespace: dev
      hosts:
        - swagger.dev.ourritual.com
      pathMatch:
        type: PathPrefix
        value: /transcriber
      # No urlRewrite - pass through as-is

# âš™ï¸ Backend Config for IAP (Swagger Gateway)
backendConfig:
  enabled: true
  
  # ğŸ”’ IAP Configuration for Swagger Access
  iap:
    enabled: true
    clientID: "1065179748589-1fcsfo37foa6ghcf5dao83t9el4qqk4k.apps.googleusercontent.com"
    oauthSecretName: swagger-iap-oauth
  
  # ğŸ“Œ Session Affinity
  sessionAffinity:
    affinityType: CLIENT_IP
    affinityCookieTtlSec: 3600
  
  # â±ï¸ Timeout
  timeoutSec: 30

# ğŸŒ Environment Variables (non-secret)
env:
  - name: PORT
    value: "8080"
  - name: PROJECT_ID
    value: ritual-app-dev-104fc
  - name: GCP_PROJECT_ID
    value: ritual-app-dev-104fc
  - name: ENVIRONMENT
    value: dev
  - name: LOG_LEVEL
    value: DEBUG
  - name: REGION
    value: us-east1

# â„¹ï¸ Secrets are automatically synced by External Secrets Operator
# The secret "transcriber-microservice-secrets" is managed by:
# - ExternalSecret CRD: transcriber-microservice-config (in dev namespace)
# - Source: GCP Secret Manager secret "transcriber" and "common-secrets"
# - Refresh: Every 1 hour
#
# This dummy entry ensures envFrom is rendered in deployment.yaml.
# The actual secret content is populated by ExternalSecret, not by these values.
secrets:
  - name: _managed_by_external_secrets_operator
    value: "true"

# GCP Project (for reference only, not used for secret fetching)
gcpProject: ritual-app-dev-104fc

# ğŸ” External Secrets Operator Configuration
# Automatically syncs secrets from GCP Secret Manager to Kubernetes
externalSecrets:
  enabled: true
  gcpProjectID: ritual-app-dev-104fc
  clusterName: ritual-engine-dev
  clusterLocation: us-east1
  refreshInterval: 1h
  
  # Dedicated K8s SA for External Secrets Operator to fetch secrets
  serviceAccount:
    create: true
    name: transcriber-eso-sa
    annotations:
      # This GCP SA has secret-level IAM permissions (managed by Terraform)
      iam.gke.io/gcp-service-account: transcriber-secrets-sa@ritual-app-dev-104fc.iam.gserviceaccount.com
  
  # Secrets to sync from GCP Secret Manager
  secretNames:
    - transcriber
    - common-secrets

# ğŸ­ Service Account (Workload Identity)
serviceAccount:
  create: true
  name: transcriber-sa
  annotations:
    iam.gke.io/gcp-service-account: transcriber-sa@ritual-app-dev-104fc.iam.gserviceaccount.com

# ğŸ”’ Security Context (Pod-level)
securityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000

# ğŸ”’ Container Security Context
containerSecurityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: false
  runAsNonRoot: true
  capabilities:
    drop:
      - ALL

# â¤ï¸ Health Checks (assuming service responds on /)
# Longer timeouts for heavy AI processing
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 60
  periodSeconds: 15
  timeoutSeconds: 10
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

startupProbe:
  httpGet:
    path: /
    port: 8080
  initialDelaySeconds: 0
  periodSeconds: 15
  timeoutSeconds: 5
  failureThreshold: 40  # Allow up to 10 minutes for heavy AI model loading

# ğŸ·ï¸ Labels
labels:
  app: transcriber
  team: backend
  tier: ai
  component: transcription
  workload: heavy
  managed-by: argocd

# ğŸ“ Annotations
annotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8080"
  prometheus.io/path: "/metrics"

# ğŸŒ Network Policy
networkPolicy:
  enabled: false

# ğŸ¯ Affinity (prefer spreading across nodes for heavy workload)
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app
                operator: In
                values:
                  - transcriber
          topologyKey: kubernetes.io/hostname

# ğŸ·ï¸ Node Selector
nodeSelector: {}

# ğŸ·ï¸ Tolerations
tolerations: []
